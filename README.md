# Machine Learning Tutorial for Beginners

[![Python](https://img.shields.io/badge/Python-3.7+-blue.svg)](https://python.org)
[![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange.svg)](https://jupyter.org)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.0+-green.svg)](https://scikit-learn.org)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

Un tutorial completo de **Machine Learning** utilizando un dataset real de pacientes ortop√©dicos. Este proyecto cubre tanto **aprendizaje supervisado** como **no supervisado** con implementaciones pr√°cticas en Python.

## Dataset 

**Archivo:** `column_2C_weka.csv`
- **310 registros** de pacientes ortop√©dicos
- **6 caracter√≠sticas num√©ricas** relacionadas con medidas p√©lvicas y lumbares
- **Variable objetivo:** Clasificaci√≥n binaria (Normal/Abnormal)

### Variables del Dataset

| Variable | Descripci√≥n | Tipo |
|----------|-------------|------|
| `pelvic_incidence` | Incidencia p√©lvica | Float64 |
| `pelvic_tilt numeric` | Inclinaci√≥n p√©lvica num√©rica | Float64 |
| `lumbar_lordosis_angle` | √Ångulo de lordosis lumbar | Float64 |
| `sacral_slope` | Pendiente sacra | Float64 |
| `pelvic_radius` | Radio p√©lvico | Float64 |
| `degree_spondylolisthesis` | Grado de espondilolistesis | Float64 |
| `class` | Clase (Normal/Abnormal) | Object |

### Distribuci√≥n de Clases

```
Abnormal: 210 casos (67.7%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
Normal:   100 casos (32.3%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
```

## Algoritmos Implementados

### Aprendizaje Supervisado

| Algoritmo | Accuracy/Score | Descripci√≥n |
|-----------|----------------|-------------|
| **K-Nearest Neighbors** | 88.17% | Clasificaci√≥n basada en vecinos m√°s cercanos |
| **Regresi√≥n Lineal** | R¬≤ = 0.646 | Modelo lineal para predicci√≥n continua |
| **Regresi√≥n Ridge** | Score: 0.561 | Regularizaci√≥n L2 para evitar overfitting |
| **Regresi√≥n Lasso** | Score: 0.964 | Regularizaci√≥n L1 con selecci√≥n de caracter√≠sticas |
| **Random Forest** | 84% | Ensemble de √°rboles de decisi√≥n |
| **Regresi√≥n Log√≠stica** | - | Clasificaci√≥n con curva ROC |

###  Aprendizaje No Supervisado

| Algoritmo | Descripci√≥n |
|-----------|-------------|
| **K-Means Clustering** | Agrupaci√≥n en 2 clusters |
| **PCA** | An√°lisis de componentes principales |
| **T-SNE** | Visualizaci√≥n de datos en 2D |
| **Clustering Jer√°rquico** | Dendrogramas para an√°lisis de clusters |

##  T√©cnicas de Evaluaci√≥n

- ‚úÖ **Train-Test Split** (70%-30%)
- ‚úÖ **Cross Validation** (5-fold)
- ‚úÖ **Grid Search** para optimizaci√≥n de hiperpar√°metros
- ‚úÖ **Matriz de Confusi√≥n**
- ‚úÖ **Curva ROC** y m√©tricas AUC
- ‚úÖ **M√©tricas completas:** Accuracy, Precision, Recall, F1-score

##  Preprocesamiento

- **Estandarizaci√≥n** de datos num√©ricos
- **One-hot encoding** para variables categ√≥ricas
- **Pipeline** para automatizar procesos
- **Normalizaci√≥n** para algoritmos sensibles a escala

##  Requisitos

```bash
pip install numpy pandas matplotlib seaborn scikit-learn scipy
```

### Dependencias principales:
- `numpy` - Computaci√≥n num√©rica
- `pandas` - Manipulaci√≥n de datos
- `matplotlib` - Visualizaci√≥n b√°sica
- `seaborn` - Visualizaci√≥n estad√≠stica
- `scikit-learn` - Algoritmos de ML
- `scipy` - Computaci√≥n cient√≠fica


##  Resultados Destacados

### üèÜ Mejores Resultados por Algoritmo:
- **ü•á Mejor Score General:** Lasso Regression (0.964)
- **ü•à Mejor Accuracy:** KNN con K=18 (88.17%)
- **ü•â Mejor Balance:** Random Forest (84% accuracy)

###  Caracter√≠sticas M√°s Importantes:
Seg√∫n el an√°lisis Lasso, las caracter√≠sticas m√°s relevantes son:
1. `pelvic_incidence` (coeficiente: 0.825)
2. `pelvic_tilt numeric` (coeficiente: -0.721)

###  Insights del Dataset:
- ‚úÖ **Dataset balanceado** - No requiere t√©cnicas especiales de balanceo
- ‚úÖ **Sin valores faltantes** - Datos limpios y completos
- ‚úÖ **Correlaciones moderadas** - Buenas para ML

## Conceptos Clave Aprendidos

###  Supervisado:
- Diferencia entre overfitting y underfitting
- Importancia de la validaci√≥n cruzada
- Optimizaci√≥n de hiperpar√°metros
- Interpretaci√≥n de m√©tricas de evaluaci√≥n

###  No Supervisado:
- Clustering y evaluaci√≥n de clusters
- Reducci√≥n de dimensionalidad
- Visualizaci√≥n de datos multidimensionales

##  Preguntas de Examen

### Conceptuales:
- ¬øQu√© es el aprendizaje supervisado vs no supervisado?
- ¬øPor qu√© es importante dividir los datos en train/test?
- ¬øQu√© es overfitting y c√≥mo evitarlo?
- ¬øCu√°l es la diferencia entre Ridge y Lasso?

### T√©cnicas:
- ¬øC√≥mo funciona el algoritmo KNN?
- ¬øQu√© mide el R¬≤ en regresi√≥n?
- ¬øC√≥mo interpretar una matriz de confusi√≥n?
- ¬øPara qu√© sirve PCA?

##  Estructura del Proyecto

```
machine-learning-tutorial/
‚îú‚îÄ‚îÄ README.md                                    
‚îú‚îÄ‚îÄ machine-learning-tutorial-for-beginners.ipynb 

``` 


##  Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request



