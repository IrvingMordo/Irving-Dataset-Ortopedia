# ğŸ§  Machine Learning Tutorial for Beginners

[![Python](https://img.shields.io/badge/Python-3.7+-blue.svg)](https://python.org)
[![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange.svg)](https://jupyter.org)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.0+-green.svg)](https://scikit-learn.org)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

Un tutorial completo de **Machine Learning** utilizando un dataset real de pacientes ortopÃ©dicos. Este proyecto cubre tanto **aprendizaje supervisado** como **no supervisado** con implementaciones prÃ¡cticas en Python.

## ğŸ“Š Dataset

**Archivo:** `column_2C_weka.csv`
- **310 registros** de pacientes ortopÃ©dicos
- **6 caracterÃ­sticas numÃ©ricas** relacionadas con medidas pÃ©lvicas y lumbares
- **Variable objetivo:** ClasificaciÃ³n binaria (Normal/Abnormal)

### ğŸ” Variables del Dataset

| Variable | DescripciÃ³n | Tipo |
|----------|-------------|------|
| `pelvic_incidence` | Incidencia pÃ©lvica | Float64 |
| `pelvic_tilt numeric` | InclinaciÃ³n pÃ©lvica numÃ©rica | Float64 |
| `lumbar_lordosis_angle` | Ãngulo de lordosis lumbar | Float64 |
| `sacral_slope` | Pendiente sacra | Float64 |
| `pelvic_radius` | Radio pÃ©lvico | Float64 |
| `degree_spondylolisthesis` | Grado de espondilolistesis | Float64 |
| `class` | Clase (Normal/Abnormal) | Object |

### ğŸ“ˆ DistribuciÃ³n de Clases

```
Abnormal: 210 casos (67.7%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Normal:   100 casos (32.3%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
```

## ğŸ¤– Algoritmos Implementados

### ğŸ“š Aprendizaje Supervisado

| Algoritmo | Accuracy/Score | DescripciÃ³n |
|-----------|----------------|-------------|
| **K-Nearest Neighbors** | 88.17% | ClasificaciÃ³n basada en vecinos mÃ¡s cercanos |
| **RegresiÃ³n Lineal** | RÂ² = 0.646 | Modelo lineal para predicciÃ³n continua |
| **RegresiÃ³n Ridge** | Score: 0.561 | RegularizaciÃ³n L2 para evitar overfitting |
| **RegresiÃ³n Lasso** | Score: 0.964 | RegularizaciÃ³n L1 con selecciÃ³n de caracterÃ­sticas |
| **Random Forest** | 84% | Ensemble de Ã¡rboles de decisiÃ³n |
| **RegresiÃ³n LogÃ­stica** | - | ClasificaciÃ³n con curva ROC |

### ğŸ” Aprendizaje No Supervisado

| Algoritmo | DescripciÃ³n |
|-----------|-------------|
| **K-Means Clustering** | AgrupaciÃ³n en 2 clusters |
| **PCA** | AnÃ¡lisis de componentes principales |
| **T-SNE** | VisualizaciÃ³n de datos en 2D |
| **Clustering JerÃ¡rquico** | Dendrogramas para anÃ¡lisis de clusters |

## ğŸ› ï¸ TÃ©cnicas de EvaluaciÃ³n

- âœ… **Train-Test Split** (70%-30%)
- âœ… **Cross Validation** (5-fold)
- âœ… **Grid Search** para optimizaciÃ³n de hiperparÃ¡metros
- âœ… **Matriz de ConfusiÃ³n**
- âœ… **Curva ROC** y mÃ©tricas AUC
- âœ… **MÃ©tricas completas:** Accuracy, Precision, Recall, F1-score

## ğŸ”§ Preprocesamiento

- **EstandarizaciÃ³n** de datos numÃ©ricos
- **One-hot encoding** para variables categÃ³ricas
- **Pipeline** para automatizar procesos
- **NormalizaciÃ³n** para algoritmos sensibles a escala

## ğŸ“‹ Requisitos

```bash
pip install numpy pandas matplotlib seaborn scikit-learn scipy
```

### Dependencias principales:
- `numpy` - ComputaciÃ³n numÃ©rica
- `pandas` - ManipulaciÃ³n de datos
- `matplotlib` - VisualizaciÃ³n bÃ¡sica
- `seaborn` - VisualizaciÃ³n estadÃ­stica
- `scikit-learn` - Algoritmos de ML
- `scipy` - ComputaciÃ³n cientÃ­fica

## ğŸš€ Uso

1. **Clona el repositorio:**
   ```bash
   git clone https://github.com/IrvingMordo26/machine-learning-tutorial.git
   cd machine-learning-tutorial
   ```

2. **Instala las dependencias:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Abre el notebook:**
   ```bash
   jupyter notebook machine-learning-tutorial-for-beginners.ipynb
   ```

4. **Ejecuta las celdas** para reproducir todos los resultados

## ğŸ“Š Resultados Destacados

### ğŸ† Mejores Resultados por Algoritmo:
- **ğŸ¥‡ Mejor Score General:** Lasso Regression (0.964)
- **ğŸ¥ˆ Mejor Accuracy:** KNN con K=18 (88.17%)
- **ğŸ¥‰ Mejor Balance:** Random Forest (84% accuracy)

### ğŸ” CaracterÃ­sticas MÃ¡s Importantes:
SegÃºn el anÃ¡lisis Lasso, las caracterÃ­sticas mÃ¡s relevantes son:
1. `pelvic_incidence` (coeficiente: 0.825)
2. `pelvic_tilt numeric` (coeficiente: -0.721)

### ğŸ“ˆ Insights del Dataset:
- âœ… **Dataset balanceado** - No requiere tÃ©cnicas especiales de balanceo
- âœ… **Sin valores faltantes** - Datos limpios y completos
- âœ… **Correlaciones moderadas** - Buenas para ML

## ğŸ“š Conceptos Clave Aprendidos

### ğŸ¯ Supervisado:
- Diferencia entre overfitting y underfitting
- Importancia de la validaciÃ³n cruzada
- OptimizaciÃ³n de hiperparÃ¡metros
- InterpretaciÃ³n de mÃ©tricas de evaluaciÃ³n

### ğŸ” No Supervisado:
- Clustering y evaluaciÃ³n de clusters
- ReducciÃ³n de dimensionalidad
- VisualizaciÃ³n de datos multidimensionales

## ğŸ“ Preguntas de Examen

### Conceptuales:
- Â¿QuÃ© es el aprendizaje supervisado vs no supervisado?
- Â¿Por quÃ© es importante dividir los datos en train/test?
- Â¿QuÃ© es overfitting y cÃ³mo evitarlo?
- Â¿CuÃ¡l es la diferencia entre Ridge y Lasso?

### TÃ©cnicas:
- Â¿CÃ³mo funciona el algoritmo KNN?
- Â¿QuÃ© mide el RÂ² en regresiÃ³n?
- Â¿CÃ³mo interpretar una matriz de confusiÃ³n?
- Â¿Para quÃ© sirve PCA?

## ğŸ“ Estructura del Proyecto

```
machine-learning-tutorial/
â”œâ”€â”€ README.md                                    # Este archivo
â”œâ”€â”€ machine-learning-tutorial-for-beginners.ipynb # Notebook principal
â”œâ”€â”€ requirements.txt                             # Dependencias
â””â”€â”€ data/                                       # Datos (si se agregan)
    â””â”€â”€ column_2C_weka.csv
```

## ğŸ‘¨â€ğŸ’» Autor

**Irving Morales**  
ğŸ“§ Email: 220732@utxicotepec.edu.mx  
ğŸ“ Estudiante de Machine Learning  
ğŸ”— GitHub: [@IrvingMordo26](https://github.com/IrvingMordo26)

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“ Contacto

Si tienes preguntas sobre este tutorial o quieres colaborar, no dudes en contactarme.

---

â­ **Â¡No olvides darle una estrella al repositorio si te fue Ãºtil!** â­# Irving-Dataset-Ortopedia
